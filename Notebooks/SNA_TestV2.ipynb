{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd03b55",
   "metadata": {},
   "source": [
    "# Social Network Analysis: Eredivisie Toxicity Project\n",
    "\n",
    "This notebook performs a social network analysis (SNA) on toxic interactions related to Eredivisie football matches. It includes data preprocessing, network construction, community detection, and visualization of toxicity spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7336da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Step 1: Import packages\n",
    "# ==============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Configure plot style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b591e",
   "metadata": {},
   "source": [
    "### Load main and metadata files\n",
    "\n",
    "This section loads the two core datasets used for network analysis that were created earlier in the pipeline:\n",
    "\n",
    "- `final_sna_dataframe.csv`: the full dataset of tweets and replies enriched with toxicity scores and thread structure.\n",
    "- `toxic_match_metadata_cleaned.csv`: structured metadata per match, including team names, dates, and manually defined toxicity-triggering events.\n",
    "\n",
    "These two datasets form the basis for constructing and analyzing reply networks across matches and clubs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af70f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset shape: (23478, 17)\n",
      "Metadata shape: (79, 14)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 2: Load main and metadata files\n",
    "# ==============================================\n",
    "\n",
    "# Load main tweet + reply data\n",
    "sna_df = pd.read_csv(\"final_sna_dataframe.csv\")\n",
    "\n",
    "# Load metadata (matches, teams, event triggers)\n",
    "match_metadata = pd.read_csv(\"toxic_match_metadata_cleaned.csv\")\n",
    "\n",
    "# Preview structure\n",
    "print(\"Main dataset shape:\", sna_df.shape)\n",
    "print(\"Metadata shape:\", match_metadata.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff78bf5",
   "metadata": {},
   "source": [
    "### Clean and prepare tweet data (with URL structure)\n",
    "\n",
    "This step filters and standardizes the dataset to ensure that reply relationships can be traced accurately across match and club networks.\n",
    "\n",
    "Key actions include:\n",
    "\n",
    "- Selecting only the columns relevant for network construction and visualization.\n",
    "- Dropping entries missing critical identifiers (`match_id`, `author`, or `tweet_url`).\n",
    "- Cleaning and lowercasing all tweet and parent URLs for consistent matching.\n",
    "- Converting timestamps into datetime objects for timeline visualizations.\n",
    "- Reconstructing the `parent_author` field using a mapping from `parent_url → author`, ensuring more reliable edge definitions even when scraped data is incomplete.\n",
    "\n",
    "This preparation step is essential for building valid reply graphs and avoiding structural gaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2cce5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Step 3: Clean and prepare tweet data (with URL structure)\n",
    "# ==============================================\n",
    "\n",
    "# Select key columns for SNA\n",
    "columns_to_keep = [\n",
    "    \"match_id\", \"author\", \"text\", \"timestamp\", \"team_handle\", \n",
    "    \"final_toxicity_label\", \"tweet_url\", \"parent_url\", \"thread_depth\", \n",
    "    \"original_parent_author\"  # make sure this is retained if present\n",
    "]\n",
    "\n",
    "# Drop rows without match_id, author, or tweet_url\n",
    "sna_df = sna_df[columns_to_keep].dropna(subset=[\"match_id\", \"author\", \"tweet_url\"])\n",
    "\n",
    "# Standardize URLs for safe tracing\n",
    "sna_df[\"tweet_url\"] = sna_df[\"tweet_url\"].astype(str).str.strip().str.lower()\n",
    "sna_df[\"parent_url\"] = sna_df[\"parent_url\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Convert timestamps\n",
    "sna_df[\"timestamp\"] = pd.to_datetime(sna_df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "# Rebuild parent_author using tweet_url → author map\n",
    "url_to_author = sna_df.set_index(\"tweet_url\")[\"author\"].to_dict()\n",
    "\n",
    "# Use mapping where possible; fallback to original scraped reply field if needed\n",
    "mapped_authors = sna_df[\"parent_url\"].map(url_to_author)\n",
    "sna_df[\"parent_author\"] = mapped_authors.combine_first(sna_df[\"original_parent_author\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c96b2",
   "metadata": {},
   "source": [
    "### Add event trigger information\n",
    "\n",
    "This step enriches the tweet dataset with metadata about emotionally charged match events that are likely to trigger online toxicity. These include:\n",
    "\n",
    "- **Red cards**\n",
    "- **Controversial referee decisions**\n",
    "- **Player mistakes**\n",
    "- **Other custom-labeled trigger types**\n",
    "\n",
    "The selected columns from the match metadata are merged into the main `sna_df` using the `match_id` as a key. This allows later analysis to connect spikes in toxicity or engagement to real-world in-game incidents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3759a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Step 4: Add event trigger information\n",
    "# ==============================================\n",
    "\n",
    "# Select trigger columns from match metadata\n",
    "trigger_columns = [\"match_id\", \"trigger_types\", \"red_card\", \"controversie\", \"player_error\"]\n",
    "\n",
    "# Merge into main SNA dataset\n",
    "sna_df = pd.merge(\n",
    "    sna_df,\n",
    "    match_metadata[trigger_columns],\n",
    "    on=\"match_id\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79678c72",
   "metadata": {},
   "source": [
    "## Construct per-match reply networks\n",
    "\n",
    "Now that I have cleaned and merged the tweets and replies into a single dataset, I can construct the interaction network.\n",
    "\n",
    "Each node in this network represents a unique Twitter user. A directed edge is created from user A to user B if A replied to B. This network helps me analyze the structure and dynamics of conversations surrounding Eredivisie matches.\n",
    "\n",
    "I focus only on replies with valid `author` and `in_reply_to_user` values to ensure edges reflect meaningful interactions.\n",
    "\n",
    "Key actions in this step:\n",
    "- Filter relevant reply rows\n",
    "- Create a directed edge list: source = replier, target = person replied to\n",
    "- Build a directed graph using NetworkX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9faaf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match M001: 65 nodes, 72 edges\n",
      "Match M002: 34 nodes, 37 edges\n",
      "Match M003: 41 nodes, 44 edges\n",
      "Match M004: 42 nodes, 44 edges\n",
      "Match M005: 72 nodes, 85 edges\n",
      "Match M006: 192 nodes, 253 edges\n",
      "Match M007: 19 nodes, 18 edges\n",
      "Match M008: 258 nodes, 304 edges\n",
      "Match M009: 58 nodes, 59 edges\n",
      "Match M010: 478 nodes, 611 edges\n",
      "Match M011: 131 nodes, 139 edges\n",
      "Match M012: 85 nodes, 88 edges\n",
      "Match M013: 26 nodes, 28 edges\n",
      "Match M014: 164 nodes, 193 edges\n",
      "Match M015: 3 nodes, 2 edges\n",
      "Match M016: 72 nodes, 76 edges\n",
      "Match M017: 119 nodes, 140 edges\n",
      "Match M018: 47 nodes, 52 edges\n",
      "Match M019: 5 nodes, 3 edges\n",
      "Match M020: 238 nodes, 276 edges\n",
      "Match M021: 64 nodes, 74 edges\n",
      "Match M022: 117 nodes, 136 edges\n",
      "Match M023: 175 nodes, 220 edges\n",
      "Match M024: 49 nodes, 54 edges\n",
      "Match M025: 38 nodes, 42 edges\n",
      "Match M026: 201 nodes, 234 edges\n",
      "Match M027: 38 nodes, 38 edges\n",
      "Match M028: 125 nodes, 141 edges\n",
      "Match M029: 534 nodes, 736 edges\n",
      "Match M030: 209 nodes, 263 edges\n",
      "Match M031: 13 nodes, 13 edges\n",
      "Match M032: 71 nodes, 83 edges\n",
      "Match M033: 28 nodes, 37 edges\n",
      "Match M034: 22 nodes, 21 edges\n",
      "Match M035: 452 nodes, 580 edges\n",
      "Match M036: 40 nodes, 42 edges\n",
      "Match M037: 119 nodes, 150 edges\n",
      "Match M038: 106 nodes, 130 edges\n",
      "Match M039: 284 nodes, 326 edges\n",
      "Match M040: 261 nodes, 359 edges\n",
      "Match M041: 7 nodes, 6 edges\n",
      "Match M042: 321 nodes, 381 edges\n",
      "Match M043: 84 nodes, 111 edges\n",
      "Match M044: 105 nodes, 113 edges\n",
      "Match M045: 117 nodes, 147 edges\n",
      "Match M046: 435 nodes, 575 edges\n",
      "Match M047: 86 nodes, 104 edges\n",
      "Match M048: 103 nodes, 136 edges\n",
      "Match M049: 82 nodes, 108 edges\n",
      "Match M050: 180 nodes, 225 edges\n",
      "Match M051: 338 nodes, 437 edges\n",
      "Match M052: 97 nodes, 108 edges\n",
      "Match M053: 3 nodes, 2 edges\n",
      "Match M054: 36 nodes, 38 edges\n",
      "Match M055: 286 nodes, 386 edges\n",
      "Match M056: 64 nodes, 84 edges\n",
      "Match M057: 4 nodes, 3 edges\n",
      "Match M058: 965 nodes, 1355 edges\n",
      "Match M059: 79 nodes, 100 edges\n",
      "Match M060: 54 nodes, 68 edges\n",
      "Match M061: 29 nodes, 29 edges\n",
      "Match M062: 53 nodes, 68 edges\n",
      "Match M063: 216 nodes, 282 edges\n",
      "Match M064: 124 nodes, 157 edges\n",
      "Match M065: 2 nodes, 1 edges\n",
      "Match M066: 261 nodes, 314 edges\n",
      "Match M067: 2 nodes, 1 edges\n",
      "Match M068: 41 nodes, 50 edges\n",
      "Match M069: 58 nodes, 60 edges\n",
      "Match M070: 449 nodes, 584 edges\n",
      "Match M071: 388 nodes, 521 edges\n",
      "Match M072: 71 nodes, 81 edges\n",
      "Match M073: 36 nodes, 42 edges\n",
      "Match M074: 38 nodes, 38 edges\n",
      "Match M075: 592 nodes, 808 edges\n",
      "Match M076: 170 nodes, 205 edges\n",
      "Match M077: 228 nodes, 282 edges\n",
      "Match M078: 32 nodes, 37 edges\n",
      "Match M079: 183 nodes, 217 edges\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 5a: Create per-match reply networks\n",
    "# ==============================================\n",
    "\n",
    "# === Handle normalization ===\n",
    "def normalize_handle(x):\n",
    "    return str(x).lower().replace(\"@\", \"\").strip()\n",
    "\n",
    "# === Dictionary to store graphs per match ===\n",
    "match_networks = {}\n",
    "\n",
    "for match_id, match_df in sna_df.groupby(\"match_id\"):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # 1. Add reply edges: normalized author → parent_author\n",
    "    for _, row in match_df.iterrows():\n",
    "        author = normalize_handle(row[\"author\"])\n",
    "        parent = normalize_handle(row[\"parent_author\"])\n",
    "        if pd.notna(author) and pd.notna(parent) and author != parent:\n",
    "            G.add_edge(author, parent, match_id=match_id)\n",
    "\n",
    "    # 2. Add timeline authors as isolated nodes if not already in graph\n",
    "    timeline_authors = match_df[match_df[\"thread_depth\"] == 0][\"author\"].dropna().unique()\n",
    "    for author in timeline_authors:\n",
    "        norm_author = normalize_handle(author)\n",
    "        if norm_author not in G:\n",
    "            G.add_node(norm_author)\n",
    "\n",
    "    match_networks[match_id] = G\n",
    "    print(f\"Match {match_id}: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# Save the match networks as a pickle file\n",
    "with open(\"C:/Master/Master project/match_networks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(match_networks, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc0b40",
   "metadata": {},
   "source": [
    "## Construct per-club reply networks\n",
    "\n",
    "To analyze interaction patterns at the club level, I create separate reply networks for each Eredivisie club based on the `team_handle` associated with the tweets.\n",
    "\n",
    "Each node in these networks represents a Twitter user. A directed edge is drawn from the reply author to the user they replied to. In addition to interaction edges, I also add timeline authors (original posters with `thread_depth == 0`) as isolated nodes, even if they didn’t participate in replies, to preserve their presence in the network.\n",
    "\n",
    "Key actions in this step:\n",
    "- Group the dataset by `team_handle` to process each club separately\n",
    "- Create directed edges from repliers to parent authors\n",
    "- Add isolated nodes for timeline authors without interactions\n",
    "- Store each club’s graph in a dictionary and save it to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fb0dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFCAjax: 2269 nodes, 4234 edges\n",
      "AZAlkmaar: 343 nodes, 506 edges\n",
      "AlmereCityFC: 75 nodes, 78 edges\n",
      "Feyenoord: 1508 nodes, 2764 edges\n",
      "FortunaSittard: 80 nodes, 89 edges\n",
      "GAEagles: 184 nodes, 211 edges\n",
      "HeraclesAlmelo: 95 nodes, 103 edges\n",
      "NACnl: 243 nodes, 322 edges\n",
      "PECZwolle: 258 nodes, 328 edges\n",
      "PSV: 1348 nodes, 2132 edges\n",
      "RKCWAALWIJK: 84 nodes, 93 edges\n",
      "SpartaRotterdam: 162 nodes, 266 edges\n",
      "WillemII: 84 nodes, 99 edges\n",
      "fcgroningen: 214 nodes, 300 edges\n",
      "fctwente: 747 nodes, 1178 edges\n",
      "fcutrecht: 201 nodes, 265 edges\n",
      "necnijmegen: 158 nodes, 224 edges\n",
      "scHeerenveen: 128 nodes, 176 edges\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 5b: Create per-club reply networks (with isolated timeline authors)\n",
    "# ==============================================\n",
    "\n",
    "# Helper to normalize usernames\n",
    "def normalize_handle(x):\n",
    "    return str(x).lower().replace(\"@\", \"\").strip()\n",
    "\n",
    "# Dictionary to store graphs per club\n",
    "club_networks = {}\n",
    "\n",
    "for club_name, club_df in sna_df.groupby(\"team_handle\"):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # 1. Add reply edges: normalized author → parent_author\n",
    "    for _, row in club_df.iterrows():\n",
    "        author = normalize_handle(row[\"author\"])\n",
    "        parent = normalize_handle(row[\"parent_author\"])\n",
    "\n",
    "        if pd.notna(author) and pd.notna(parent) and author != parent:\n",
    "            G.add_edge(author, parent, club=club_name)\n",
    "\n",
    "    # 2. Add timeline authors (thread_depth = 0) as isolated nodes\n",
    "    timeline_authors = club_df[club_df[\"thread_depth\"] == 0][\"author\"].dropna().unique()\n",
    "    for author in timeline_authors:\n",
    "        norm_author = normalize_handle(author)\n",
    "        if norm_author not in G:\n",
    "            G.add_node(norm_author)\n",
    "\n",
    "    club_networks[club_name] = G\n",
    "    print(f\"{club_name}: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "with open(\"C:/Master/Master project/club_networks.pkl\", \"wb\") as f:\n",
    "    pickle.dump(club_networks, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030897ad",
   "metadata": {},
   "source": [
    "## Compute SNA metrics per match\n",
    "\n",
    "In this step, I compute key social network analysis (SNA) metrics for each match-specific reply graph. These metrics help quantify the structure and dynamics of user interactions during each match.\n",
    "\n",
    "For each `match_id`, I calculate:\n",
    "\n",
    "- **Degree Centrality**: Measures how many direct connections a user has.\n",
    "- **Betweenness Centrality**: Captures how often a user lies on the shortest path between others, indicating influence or gatekeeping.\n",
    "- **Clustering Coefficient**: Reflects how tightly users in the network tend to cluster together (measured on the undirected version of the graph).\n",
    "\n",
    "I then compute the average value of each metric across all nodes in the graph and store the results in a summary DataFrame (`match_metrics_df`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "match_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_nodes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_edges",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_degree_centrality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_betweenness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_clustering",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "61f8fd1d-f362-405a-9bdf-bc76ad2064c0",
       "rows": [
        [
         "57",
         "M058",
         "965",
         "1355",
         "0.0029131640616601746",
         "0.00010832398512779696",
         "0.025262681453898077"
        ],
        [
         "74",
         "M075",
         "592",
         "808",
         "0.004618832029999615",
         "5.467859238400405e-05",
         "0.02254352691095645"
        ],
        [
         "28",
         "M029",
         "534",
         "736",
         "0.00517177168314461",
         "0.0005166660036054679",
         "0.007118932825269921"
        ],
        [
         "9",
         "M010",
         "478",
         "611",
         "0.005359508083120577",
         "2.767876446123303e-05",
         "0.03384187253992681"
        ],
        [
         "34",
         "M035",
         "452",
         "580",
         "0.00569040284127708",
         "3.10137856004465e-05",
         "0.022047925351212812"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>avg_degree_centrality</th>\n",
       "      <th>avg_betweenness</th>\n",
       "      <th>avg_clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>M058</td>\n",
       "      <td>965</td>\n",
       "      <td>1355</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.025263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>M075</td>\n",
       "      <td>592</td>\n",
       "      <td>808</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.022544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>M029</td>\n",
       "      <td>534</td>\n",
       "      <td>736</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.007119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M010</td>\n",
       "      <td>478</td>\n",
       "      <td>611</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.033842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>M035</td>\n",
       "      <td>452</td>\n",
       "      <td>580</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.022048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  num_nodes  num_edges  avg_degree_centrality  avg_betweenness  \\\n",
       "57     M058        965       1355               0.002913         0.000108   \n",
       "74     M075        592        808               0.004619         0.000055   \n",
       "28     M029        534        736               0.005172         0.000517   \n",
       "9      M010        478        611               0.005360         0.000028   \n",
       "34     M035        452        580               0.005690         0.000031   \n",
       "\n",
       "    avg_clustering  \n",
       "57        0.025263  \n",
       "74        0.022544  \n",
       "28        0.007119  \n",
       "9         0.033842  \n",
       "34        0.022048  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 6: Compute SNA metrics per match\n",
    "# ==============================================\n",
    "\n",
    "match_metrics = []\n",
    "\n",
    "# Loop over each match-specific graph\n",
    "for match_id, G in match_networks.items():\n",
    "    if G.number_of_nodes() == 0:\n",
    "        continue  # Skip empty graphs\n",
    "\n",
    "    # Compute node-level metrics\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, normalized=True)\n",
    "    clustering = nx.clustering(G.to_undirected())\n",
    "\n",
    "    # Aggregate into match-level averages\n",
    "    match_metrics.append({\n",
    "        \"match_id\": match_id,\n",
    "        \"num_nodes\": G.number_of_nodes(),\n",
    "        \"num_edges\": G.number_of_edges(),\n",
    "        \"avg_degree_centrality\": sum(degree_centrality.values()) / len(degree_centrality),\n",
    "        \"avg_betweenness\": sum(betweenness_centrality.values()) / len(betweenness_centrality),\n",
    "        \"avg_clustering\": sum(clustering.values()) / len(clustering)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and preview\n",
    "match_metrics_df = pd.DataFrame(match_metrics)\n",
    "match_metrics_df.sort_values(\"num_nodes\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15a70e",
   "metadata": {},
   "source": [
    "## Compute SNA metrics per club\n",
    "\n",
    "Similar to the match-level analysis, I compute network metrics for each club-specific reply graph. These metrics provide insight into how users engage in conversations surrounding specific Eredivisie teams.\n",
    "\n",
    "For each `club` in the `club_networks` dictionary, I calculate:\n",
    "\n",
    "- **Degree Centrality**: Measures direct interactions a user has.\n",
    "- **Betweenness Centrality**: Indicates how influential a user is in the flow of information.\n",
    "- **Clustering Coefficient**: Measures the tightness of user clusters in the network.\n",
    "\n",
    "The results are aggregated into a `club_metrics_df` DataFrame, enabling comparison across clubs based on interaction structure and toxicity patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b45e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "club",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_nodes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_edges",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_degree_centrality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_betweenness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_clustering",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9f7b616b-894b-4c10-b50d-7a9a561c184f",
       "rows": [
        [
         "0",
         "AFCAjax",
         "2269",
         "4234",
         "0.0016455205231465646",
         "0.00015482620398587908",
         "0.05963079453001327"
        ],
        [
         "3",
         "Feyenoord",
         "1508",
         "2764",
         "0.002432503313449639",
         "0.00033856256586779207",
         "0.04851047735799248"
        ],
        [
         "9",
         "PSV",
         "1348",
         "2132",
         "0.002348333146083548",
         "0.00030515944685435007",
         "0.04144450475871361"
        ],
        [
         "14",
         "fctwente",
         "747",
         "1178",
         "0.004227813846987608",
         "0.0004349477728102978",
         "0.074687458804799"
        ],
        [
         "1",
         "AZAlkmaar",
         "343",
         "506",
         "0.008627009701123612",
         "0.0004233607539106309",
         "0.04715614907854573"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>avg_degree_centrality</th>\n",
       "      <th>avg_betweenness</th>\n",
       "      <th>avg_clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFCAjax</td>\n",
       "      <td>2269</td>\n",
       "      <td>4234</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.059631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feyenoord</td>\n",
       "      <td>1508</td>\n",
       "      <td>2764</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.048510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSV</td>\n",
       "      <td>1348</td>\n",
       "      <td>2132</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.041445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fctwente</td>\n",
       "      <td>747</td>\n",
       "      <td>1178</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZAlkmaar</td>\n",
       "      <td>343</td>\n",
       "      <td>506</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.047156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         club  num_nodes  num_edges  avg_degree_centrality  avg_betweenness  \\\n",
       "0     AFCAjax       2269       4234               0.001646         0.000155   \n",
       "3   Feyenoord       1508       2764               0.002433         0.000339   \n",
       "9         PSV       1348       2132               0.002348         0.000305   \n",
       "14   fctwente        747       1178               0.004228         0.000435   \n",
       "1   AZAlkmaar        343        506               0.008627         0.000423   \n",
       "\n",
       "    avg_clustering  \n",
       "0         0.059631  \n",
       "3         0.048510  \n",
       "9         0.041445  \n",
       "14        0.074687  \n",
       "1         0.047156  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Step 7: Compute SNA metrics per club\n",
    "# ==============================================\n",
    "\n",
    "club_metrics = []\n",
    "\n",
    "# Loop over each club-specific graph\n",
    "for club, G in club_networks.items():\n",
    "    if G.number_of_nodes() == 0:\n",
    "        continue  # Skip empty graphs\n",
    "\n",
    "    # Compute node-level metrics\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    betweenness_centrality = nx.betweenness_centrality(G, normalized=True)\n",
    "    clustering = nx.clustering(G.to_undirected())\n",
    "\n",
    "    # Aggregate into club-level averages\n",
    "    club_metrics.append({\n",
    "        \"club\": club,\n",
    "        \"num_nodes\": G.number_of_nodes(),\n",
    "        \"num_edges\": G.number_of_edges(),\n",
    "        \"avg_degree_centrality\": sum(degree_centrality.values()) / len(degree_centrality),\n",
    "        \"avg_betweenness\": sum(betweenness_centrality.values()) / len(betweenness_centrality),\n",
    "        \"avg_clustering\": sum(clustering.values()) / len(clustering)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame and preview\n",
    "club_metrics_df = pd.DataFrame(club_metrics)\n",
    "club_metrics_df.sort_values(\"num_nodes\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323fff1",
   "metadata": {},
   "source": [
    "## References and Justification of Methods\n",
    "\n",
    "This notebook applies Social Network Analysis (SNA) techniques to visualize and analyze interactions around Eredivisie football club tweets. The development of this notebook is grounded in both academic literature and established technical tools. Below are the references used for each key component:\n",
    "\n",
    "**1. Social Network Metrics**  \n",
    "The following SNA metrics were implemented:\n",
    "- **Degree Centrality**, **Betweenness Centrality**, and **Clustering Coefficient** are core concepts in network science (Wasserman & Faust, 1994).\n",
    "- These have been applied to Twitter in research such as Himelboim et al. (2017), which explored influence structures in social media.\n",
    "\n",
    "> Wasserman, S., & Faust, K. (1994). *Social Network Analysis: Methods and Applications*. Cambridge University Press.  \n",
    "> Himelboim, I., Smith, M. A., Rainie, L., Shneiderman, B., & Espina, C. (2017). Classifying Twitter topic-networks using social network analysis. *Social Media + Society*, 3(1).\n",
    "\n",
    "**2. Community Detection (Louvain Algorithm)**  \n",
    "Community detection is done using the Louvain method (Blondel et al., 2008), a fast and widely used algorithm for modularity optimization in large-scale networks.\n",
    "\n",
    "> Blondel, V. D., Guillaume, J. L., Lambiotte, R., & Lefebvre, E. (2008). Fast unfolding of communities in large networks. *Journal of Statistical Mechanics: Theory and Experiment*, 2008(10), P10008.\n",
    "\n",
    "**3. Toxicity Highlighting and Node Annotation**  \n",
    "Nodes are color-coded and styled based on account type and toxicity, inspired by prior work on toxic content in Twitter SNA (Chatzakou et al., 2017).\n",
    "\n",
    "> Chatzakou, D., Kourtellis, N., Blackburn, J., De Cristofaro, E., Stringhini, G., & Vakali, A. (2017). Mean birds: Detecting aggression and bullying on Twitter. In *Proceedings of the ACM Web Science Conference* (WebSci).\n",
    "\n",
    "**4. Visualization Libraries**  \n",
    "We use NetworkX and Plotly for interactive and static graph visualization. These are standard tools for Python-based SNA:\n",
    "- NetworkX: Hagberg et al. (2008)\n",
    "- Plotly: Official documentation and open-source community examples\n",
    "\n",
    "> Hagberg, A. A., Schult, D. A., & Swart, P. J. (2008). Exploring network structure, dynamics, and function using NetworkX. In *Proceedings of the 7th Python in Science Conference* (SciPy2008), 11–15.\n",
    "\n",
    "These references justify the choice of methods used in this notebook and align with best practices in both social science research and computational SNA.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Introduction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
